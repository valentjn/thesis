\section{Test Problems}
\label{sec:53testProblems}

It is impossible to assess the capability of optimization methods
for every possible optimization problem.
The most widespread approach in literature
is the selection of a subset of specific problems
with different characteristics \term{(test problems)} and
the application of the methods to only these problems,
in the hope that the methods perform similarly in
actual application settings.

\paragraph{Trivial test functions}

When testing methods that involve sparse grid interpolation,
one has to consider that the function to be interpolated
does not satisfy a specific \term{trivial property.}
A test function $\objfun\colon \clint{\*0, \*1} \to \real$ is trivial, if
$\objfun$ is of the form
\begin{equation}
  \objfun \equiv \sum_{q=1}^m \prod_{t=1}^d \objfun_{q,t},\quad
  m \in \natz,\;\;
  \objfun_{q,t}\colon \clint{\*0, \*1} \to \real,\;\;
  \faex{q = 1, \dotsc, m}{t \in \{1, \dotsc, d\}}{
    \objfun_{q,t} \in \polyspace{1},
  }
\end{equation}
where $\polyspace{1}$ is the space of polynomials up to linear degree.
Trivial test functions are sums of tensor products of which at
least one factor is a linear polynomial.
Note that this is already fulfilled if the summands of $\objfun(\*x)$
do not depend on all coordinates $x_t$ of $\*x$.
One can show that for hat functions on sparse grids,
the hierarchical surpluses $\surplus{\*l,\*i}$ for trivial functions
vanish if $\*l \ge \*1$.
This means that trivial functions can well be approximated by hat functions
on sparse grids with boundary points, without placing any points
in the interior.
As this would distort our results,
we avoid trivial test functions in the following,
which include popular functions such as the
Branin01, Rosenbrock, and Schwefel26 functions.

\paragraph{Selection of test problems}

In the following, we select six unconstrained problems
and two constrained problems, which are listed in
\cref{tbl:optimizationProblem} and plotted in
\cref{fig:unconstrainedOptimizationProblem,fig:constrainedOptimizationProblem}.
The definitions of the problems are given in \cref{chap:a20testProblems}.
For the unconstrained case and the standard hierarchical
B-spline basis, a more exhaustive list of test functions has been
studied previously \cite{Valentin14Hierarchische}.
Gavana \cite{Gavana13Global} and Runarsson/Yao \cite{Runarsson00Stochastic}
provide a good overview of unconstrained and constrained test problems,
respectively.

\begin{table}
  \setnumberoftableheaderrows{1}%
  \begin{tabular}{%
      >{\kern\tabcolsep}=l<{\kern5mm}*{6}{+c}+l<{\kern\tabcolsep}%
    }
    \toprulec
    \headerrow
    Name&                             $d$& $m_{\ineqconfun}$& $m_{\eqconfun}$& C&    CD&   MM&   Reference\\
    \midrulec
    % Beale(2)?
    \textbf{Bra}nin\textbf{02}&       2&   0&                 0&               \yes& \yes& \yes& \cite{Munteanu98Global}\\
    %\textbf{Egg}Holder&               2&   0&                 0&               \yes& \no&  \yes& \cite{Whitley96Evaluating}\\
    \textbf{Go}ldstein\textbf{P}rice& 2&   0&                 0&               \yes& \yes& \yes& \cite{Goldstein71Descent}\\
    \textbf{Sch}wefel\textbf{06}&     2&   0&                 0&               \yes& \no&  \no&  \cite{Schwefel77Numerische}\\
    \textbf{Ack}ley&                  $d$& 0&                 0&               \yes& \yes& \yes& \cite{Ackley87Connectionist}\\
    \textbf{Alp}ine\textbf{02}&       $d$& 0&                 0&               \yes& \yes& \yes& \cite{Clerc99Swarm}\\
    \textbf{Sch}wefel\textbf{22}&     $d$& 0&                 0&               \yes& \no&  \no&  \cite{Schwefel77Numerische}\\
    \midrulec
    \textbf{G08}&                     2&   2&                 0&               \yes& \yes& \yes& \cite{Schoenauer93Constrained}\\
    \textbf{G13}&                     5&   0&                 3&               \yes& \yes& \yes& \cite{Powell69Method}\\
    \bottomrulec
  \end{tabular}
  \caption[Selection of test problems in optimization]{%
    Unconstrained \emph{(top)} and constrained \emph{(bottom)} test problems.
    The bold-faced part of the name will be used as an abbreviation.
    The remaining columns state
    the dimensionality $d$ of the objective function $\objfun$,
    the numbers $m_{\ineqconfun}$ and $m_{\eqconfun}$ of
    inequality and equality constraints,
    whether $\objfun$ is continuous in the domain
    $\clint{\*0, \*1}$ (C),
    whether $\objfun$ is continuously differentiable in the domain
    $\clint{\*0, \*1}$ (CD),
    whether $\objfun$ is multi-modal (MM, i.e.,
    whether there are multiple local minima), and
    a reference to the original literature that defines the problem.%
  }%
  \label{tbl:optimizationProblem}%
\end{table}

\begin{figure}
  \subcaptionbox{%
    Branin02%
  }[71mm]{%
    \includegraphics{optimizationProblem_1}%
  }%
  \hfill%
  \subcaptionbox{%
    GoldsteinPrice%
  }[76mm]{%
    \includegraphics{optimizationProblem_2}%
  }\\[2.5mm]%
  \subcaptionbox{%
    Schwefel06%
  }[71mm]{%
    \includegraphics{optimizationProblem_3}%
  }%
  \hfill%
  \subcaptionbox{%
    Ackley for $d = 2$%
  }[76mm]{%
    \includegraphics{optimizationProblem_4}%
  }\\[2.5mm]%
  \subcaptionbox{%
    Alpine02 for $d = 2$%
  }[71mm]{%
    \includegraphics{optimizationProblem_5}%
  }%
  \hfill%
  \subcaptionbox{%
    Schwefel22 for $d = 2$%
  }[76mm]{%
    \includegraphics{optimizationProblem_6}%
  }%
  \caption[%
    Unconstrained test problems%
  ]{%
    Bivariate test functions $\objfunscaled$ in unconstrained optimization.
    The \textcolor{C1}{red dot} indicates the location of the
    global minimum.%
  }%
  \label{fig:unconstrainedOptimizationProblem}%
\end{figure}

\begin{figure}
  \subcaptionbox{%
    G08.
    The \textcolor{C0}{blue areas} denote the inequality constraints.%
  }[72mm]{%
    \includegraphics{optimizationProblem_7}%
  }%
  \hfill%
  \subcaptionbox{%
    G13.
    Shown is a bivariate projection over $\xscaled[1]$ and $\xscaled[2]$
    onto $\xscaled[t] = \xoptscaled[t]$ for $t = 3, 4, 5$.
    The \textcolor{C0}{blue lines} denote the equality constraints.%
  }[72mm]{%
    \includegraphics{optimizationProblem_8}%
  }%
  \caption[%
    Constrained test problems%
  ]{%
    Test problems in constrained optimization.
    The \textcolor{C1}{red dot} indicates the location of the
    global minimum.%
  }%
  \label{fig:constrainedOptimizationProblem}%
\end{figure}

For each test problem, we state unscaled versions of objective functions
$\objfunscaled\colon \clint{\*a, \*b} \to \real$,
$\xscaled \to \objfunscaled(\xscaled)$
(and, if present, unscaled constraint functions
$\ineqconfunscaled$ and $\eqconfunscaled$).
The actual objective function $\objfun\colon \clint{\*0, \*1} \to \real$
can be obtained by $\objfun(\*x) := \objfunscaled(\xscaled)$
with the affine parameter transformation
$\*x = (\xscaled - \*a)/(\*b - \*a)$
(similarly for the constraint functions).

The parameter domain of some objective functions have been translated slightly
compared to the literature
to avoid that the minimum is located exactly at or close to
the center of the domain.
In this case, sparse grids would be in advantage as
they tend to place more points near the center of the domain
(especially for high dimensionalities).
