\section{Numerical Results}
\label{sec:64results}

\minitoc[-5mm]{72mm}{3}

\noindent
In this final section of the chapter,
we study optimal results of the test scenarios and
analyze interpolation and optimization errors
for topology optimization with B-spline surrogates on sparse grids.



\subsection{Methodology}
\label{sec:641methodology}

For simplicity, in the following,
we combine the functions to be interpolated,
i.e., the Cholesky factor
$\cholfactor\colon \clint{\*0, \*1} \to \real^{6 \times 6}$ and
the micro-cell density $\denscell\colon \clint{\*0, \*1} \to \real$,
to one single objective function
$\*\objfun\colon \clint{\*0, \*1} \to \real^{m+1}$.

\paragraph{Overview over offline and online phase}

Our method is divided into an offline phase and an online phase,
both of which are sketched in \cref{fig:topoOptPhases}.
The offline phase comprises
generating the spatially adaptive sparse grid
$\sgset = \{\gp{\*l_k,\*i_k} \mid k = 1, \dotsc, \ngp\}$,
solving corresponding micro-problems,
computing the Cholesky factors, and
hierarchizing the Cholesky factor entries and micro-cell densities
to obtain the sparse grid interpolant $\*\sgintp$.
Each optimization iteration of the online phase consists of
evaluating the interpolant $\*\sgintp$
for each micro-cell parameter $\*x^{(j)}$ ($j = 1, \dotsc, M$),
reconstructing the elasticity tensor $\etensor[\chol,\sparse]$ from
the Cholesky factors $\cholfactor[\sparse]$, and
solving the macro-problem to retrieve the approximated compliance value
$\compliance[\sparse](\*x^{(1)}, \dotsc, \*x^{(M)})$.%
\footnote{%
  In addition, the partial derivatives
  $\partialdiff{} \etensor[\chol,\sparse]/\partialdiff{} x_t$
  ($t = 1, \dotsc, d$)
  are evaluated using \cref{eq:choleskyFactorDerivative}.
  This is required as we employ gradient-based optimization.%
}
The superscript in $\compliance[\sparse]$ indicates that
we do not use the exact elasticity tensors to compute the compliance value.

\begin{figure}
  \tikzset{
    myCircle/.style={
      circle,
      fill=mittelblau!30,
      draw=mittelblau,
      inner sep=0.5mm,
    }
  }%
  \subcaptionbox{%
    Offline phase (without the actual grid generation).%
  }[149mm]{%
    \begin{tikzpicture}
      \node[myCircle] (points) at (0mm,0mm) {%
        $
          \begin{matrix}
            \gp{\*l_1,\*i_1},\\
            \dots,\\
            \gp{\*l_{\ngp},\*i_{\ngp}}
          \end{matrix}
        $%
      };
      \node[myCircle] (elasticityTensors) at (43mm,0mm) {%
        $
          \begin{matrix}
            \etensor(\gp{\*l_1,\*i_1}),\\
            \dots,\\
            \etensor(\gp{\*l_{\ngp},\*i_{\ngp}})
          \end{matrix}
        $%
      };
      \node[myCircle] (choleskyFactors) at (80mm,0mm) {%
        $
          \begin{matrix}
            \cholfactor(\gp{\*l_1,\*i_1}),\\
            \dots,\\
            \cholfactor(\gp{\*l_{\ngp},\*i_{\ngp}})
          \end{matrix}
        $%
      };
      \node[myCircle] (choleskyInterpolant) at (118mm,0mm) {%
        $
          \begin{matrix}
            \cholfactor[\sparse]\colon \clint{\*0, \*1}\\
            {} \to \real^{6 \times 6}
          \end{matrix}
        $%
      };
      \draw[->,draw=C0] (points) -- node[above] {%
        \footnotesize{}micro-problem%
      } (elasticityTensors);
      \draw[->,draw=C0] (elasticityTensors) -- node[above] {%
        \footnotesize{}%
        $
          \tr{\cholfactor} \cholfactor = \etensor
        $\vphantom{p}%
      } (choleskyFactors);
      \draw[->,draw=C0] (choleskyFactors) -- node[above] {%
        \footnotesize{}interpolate%
      } (choleskyInterpolant);
    \end{tikzpicture}%
  }%
  \\[2mm]%
  \subcaptionbox{%
    Online phase (one iteration of the optimizer).%
  }[149mm]{%
    \begin{tikzpicture}
      \node[myCircle] (points) at (0mm,0mm) {%
        $
          \begin{matrix}
            \*x^{(1)},\\
            \dots,\\
            \*x^{(M)}
          \end{matrix}
        $%
      };
      \node[myCircle] (choleskyFactors) at (34mm,0mm) {%
        $
          \begin{matrix}
            \cholfactor[\sparse](\*x^{(1)}),\\
            \dots,\\
            \cholfactor[\sparse](\*x^{(M)})
          \end{matrix}
        $%
      };
      \node[myCircle] (elasticityTensors) at (83mm,0mm) {%
        $
          \begin{matrix}
            \etensor[\chol,\sparse](\*x^{(1)}),\\
            \dots,\\
            \etensor[\chol,\sparse](\*x^{(M)})
          \end{matrix}
        $%
      };
      \node[myCircle] (complianceValue) at (129.5mm,0mm) {%
        $
          \begin{matrix}
            \compliance[\sparse](\*x^{(1)},\\
            \dotsc,\\
            \*x^{(M)})
          \end{matrix}
        $%
      };
      \draw[->,draw=C0] (points) -- node[above] {%
        \footnotesize{}evaluate\vphantom{p}%
      } (choleskyFactors);
      \draw[->,draw=C0] (choleskyFactors) -- node[above] {%
        \footnotesize{}%
        $
          \etensor[\chol,\sparse]
          = \tr{(\cholfactor[\sparse])} \cholfactor[\sparse]
        $\vphantom{p}%
      } (elasticityTensors);
      \draw[->,draw=C0] (elasticityTensors) -- node[above] {%
        \footnotesize{}macro-problem%
      } (complianceValue);
    \end{tikzpicture}%
  }%
  \caption[Offline and online phase for topology optimization]{%
    Offline and online phase for topology optimization.
    The interpolation of the micro-cell density with $\denscell^{\sparse}$
    (see \cref{sec:622BSplines}) has been omitted for brevity.%
  }%
  \label{fig:topoOptPhases}%
\end{figure}

\paragraph{Generation of spatially adaptive sparse grids}

We use the classical surplus-based refinement criterion
(see, e.g., \cite{Pflueger10Spatially})
to generate the spatially adaptive sparse grids
as show in \cref{alg:topoOptGridGeneration}.
The difference to common surrogate settings is that the objective function
$\*f\colon \clint{\*0, \*1} \to \real^{m+1}$
is not scalar-valued, but matrix-valued.
As the components of $\cholfactor$ cannot be evaluated individually,
the adaptivity criterion has to consider all entries at once
to avoid performing unnecessary evaluations.
We use the surpluses in the piecewise linear hierarchical basis,
as their absolute values correlate with the second mixed derivative
of the objective function due to \eqref{eq:surplusIntegral}.

\begin{algorithm}
  \begin{algorithmic}[1]
    \Function{$\sgset = \texttt{offlinePhase}$}{%
      $\*\objfun$, $n$, $b$, $\*c$, $l_{\max}$, $\varepsilon$,
      $\ngp_{\mathrm{refine}}$%
    }
      \State{$\sgset \gets \coarseregsgset{n}{d}{b}$}
      \Comment{initial regular sparse grid}%
      \While{\True}
        \State{$\ngp \gets \setsize{\sgset}$}
        \Comment{number of grid points}%
        \State{%
          Let $(\surplus{\*l_{k'},\*i_{k'}})_{k' = 1, \dotsc, \ngp}$
          satisfy $
            \fa{k = 1, \dotsc, \ngp}{
              \sum_{k'=1}^{\ngp} \vsurplus_{\*l_{k'},\*i_{k'}}
              \bspl{\*l_{k'},\*i_{k'}}{1}(\gp{\*l_k,\*i_k})
              = \*\objfun(\gp{\*l_k,\*i_k})
            }
          $%
        }
        \ForOneLine{$k = 1, \dotsc, \ngp$}{%
          $\beta_k \gets \tr{\*c} \abs{\vsurplus_{\*l,\*i}}$%
        }
        \Comment{combine surpluses to a scalar value}%
        \State{%
          $
            \liset^\ast \gets \{
              k = 1, \dotsc, \ngp \mid
              \ex{\gp{\*l,\*i} \notin \sgset}{
                \gp{\*l_k,\*i_k} \to \gp{\*l,\*i}
              },\,
              \norm[\infty]{\*l_k} < l_{\max},\,
              \abs{\surplus{\*l_k,\*i_k}} > \varepsilon
            \}
          $%
        }
        \IfOneLine{$\liset^\ast = \emptyset$}{\Break{}}
        \Comment{stop when there are not refinable grid points left}%
        \State{%
          Refine $\le \ngp_{\mathrm{refine}}$ of the points
          $\{\gp{\*l_k,\*i_k} \in \sgset \mid k \in \liset^\ast\}$
          with largest $\abs{\beta_k}$%
        }
      \EndWhile{}
    \EndFunction{}
  \end{algorithmic}
  \caption[%
    Generation of spatially adaptive sparse grids for topology optimization%
  ]{%
    Generation of spatially adaptive sparse grids for topology optimization.
    Inputs are
    the objective function $\*f\colon \clint{\*0, \*1} \to \real^{m+1}$
    (combination of Cholesky factors of elasticity tensors and
    micro-cell densities),
    the level $n \ge d$ and boundary parameter $b \in \natz$ of the
    initial regular sparse grid,
    the vector $\*c \in \real^d$ of coefficients with which the
    absolute values of the entries of the surpluses are combined,
    the maximal level $l_{\max} \in \nat$,
    the refinement threshold $\varepsilon \in \posreal$, and
    the number $\ngp_{\mathrm{refine}} \in \nat$ of points to refine
    in each iteration.
    Output is the spatially adaptive sparse grid $\sgset$.%
  }%
  \label{alg:topoOptGridGeneration}%
\end{algorithm}

\paragraph{Parameter bounds}

In the micro-cell models presented in \cref{sec:631models},
extreme micro-cell parameters near zero or one may cause problems
with the resulting elasticity tensors.
For instance, the elasticity tensor entries corresponding to
the 2D cross model are discontinuous near the lines $x_1 = 1$ or $x_2 = 1$
\multicite{Huebner14Mehrdimensionale,Valentin14Hierarchische}.
This is due to the fact the micro-cell is completely filled with material
on these lines,
independent of the other micro-cell parameter that is not one.
Similar issues occur for the other models and the shearing angles.
Hence, we have to restrict the range of the feasible micro-cell parameters,
i.e., the sparse grid points $\*x$ are still defined on the unit hyper-cube
$\clint{\*0, \*1}$,
but the actual micro-cell parameters $\xscaled$ are retrieved by an
affine transformation $\xscaled := \*a + (\*b - \*a) \*x$.
For the models in \cref{sec:631models},
we restrict the bar widths to $\clint{0.01, 0.99}$ and
the shearing angles to $\clint{-0.35\pi, 0.35\pi}$.

\paragraph{Software, algorithms, and domain discretization}

The micro-problems and macro-problems are solved with the \fem
implemented in the \fem software package CFS++ \cite{Kaltenbacher10Advanced}.%
\footnote{%
  \url{http://www.lse.uni-erlangen.de/cfs/}%
}
The micro-problems were discretized by dividing the micro-cells into
$128 \times 128$ elements (models in two dimensions) or
$16 \times 16 \times 16$ elements (models in three dimensions).
Constructing the sparse grids (offline phase) was done via a MATLAB code,
while the evaluations of the interpolants (online phase) were performed
by the sparse grid toolbox \sgpp \cite{Pflueger10Spatially}.%
\footnote{%
  \url{http://sgpp.sparsegrids.org/}%
}
For the solution of the emerging optimization problems,
a sequential quadratic programming method was employed
(see \cref{sec:513gradientBasedConstrained}).



\subsection{Error Sources}
\label{sec:642errorSources}

There are multiple sources that contribute to the numerical error
of our method:

\begin{enumerate}
  \item
  Discretization of the micro-problem
  (i.e., the elasticity tensors $\etensor$ are inaccurate)
  
  \item
  Sparse grid interpolation
  (i.e., $\etensor[\sparse] \not= \etensor$)
  
  \item
  Reconstruction of elasticity tensors with Cholesky factors
  (i.e., $\etensor[\chol,\sparse] \not= \etensor[\sparse]$)
  
  \item
  Discretization of the macro-problem
  (i.e., the compliance $\compliance$ is inaccurate)
  
  \item
  Optimization
  (i.e., the global minimum found by the optimizer is inaccurate)
  
  \item
  Floating-point rounding errors
  (i.e., arithmetical operations are inaccurate)
\end{enumerate}

\noindent
Errors of type~6 are always present and will not be analyzed in this chapter.
Errors of type~1 and~4 are intrinsic to the homogenization approach
and will also not be discussed here.
%The errors of type 2 and 5 have already been analyzed in
%\cref{chap:50optimization}.
Therefore, in the remainder of this chapter,
we will analyze the errors of types~2 and~3 (\cref{sec:643interpolation})
and of type~5 (\cref{sec:644optimization}).



\subsection{Interpolation Error}
\label{sec:643interpolation}

\begin{figure}
  \subcaptionbox{%
    $\norm[2]{\etensor(\*x) - \etensor[\sparse](\*x)}$%
  }[63mm]{%
    \includegraphics{topoOptInterpolationPointwise_1}%
  }%
  \hspace{3mm}%
  \subcaptionbox{%
    $\norm[2]{\etensor(\*x) - \etensor[\chol,\sparse](\*x)}$%
  }[63mm]{%
    \includegraphics{topoOptInterpolationPointwise_2}%
  }%
  \hfill%
  \includegraphics{topoOptInterpolationPointwise_3}%
  \caption[Pointwise spectral error for the 2D cross model]{%
    Pointwise spectral error for the 2D cross model and
    hierarchical cubic B-splines on a
    spatially adaptive sparse grid with $\ngp = 1320$ points for
    the direct interpolation of elasticity tensors \emph{(left)} and
    the interpolation of Cholesky factors \emph{(right).}%
  }%
  \label{fig:topoOptInterpolationErrorPointwise}%
\end{figure}

\begin{figure}
  \hspace*{5mm}%
  \includegraphics{topoOptInterpolation_3}%
  \hfill%
  \raisebox{0.5mm}{\includegraphics{topoOptInterpolation_4}}%
  \\[2mm]%
  \subcaptionbox{%
    2D cross (different degrees)%
  }[72mm]{%
    \includegraphics{topoOptInterpolation_1}%
  }%
  \hfill%
  \subcaptionbox{%
    Other micro-cell models ($p = 3$)%
  }[72mm]{%
    \includegraphics{topoOptInterpolation_2}%
  }%
  \caption[Convergence of relative $L^2$ spectral errors]{%
    Convergence of relative $\Ltwo$ spectral errors
    over the increasing number $\ngp$ of spatially adaptive grid points
    (i.e., for decreasing tolerance $\varepsilon$)
    for the 2D cross model without or with Cholesky factor interpolation
    and different degrees $p$ \emph{(left)} and
    for the other five micro-cell models and cubic degree \emph{(right)}.%
  }%
  \label{fig:topoOptInterpolationErrorBasisFunctions}%
\end{figure}

\dummytext[4]{}



\subsection{Optimized Structures and Optimization Error}
\label{sec:644optimization}

\begin{table}
  \setnumberoftableheaderrows{1}%
  \begin{tabular}{%
    >{\kern\tabcolsep}=l<{\kern5mm}*{6}{+c}<{\kern\tabcolsep}%
  }
    \toprulec
    \headerrow
    Scenario&       2D-C&   2D-FC&  2D-SC&  2D-SFC& 3D-C&   3D-SC\\
    \midrulec
    2D cantilever&  XX.XXX& XX.XXX& XX.XXX& XX.XXX& ---&    ---\\
    2D L shape&     XX.XXX& XX.XXX& XX.XXX& XX.XXX& ---&    ---\\
    \midrulec
    3D cantilever&  ---&    ---&    ---&    ---&    XX.XXX& XX.XXX\\
    3D center load& ---&    ---&    ---&    ---&    XX.XXX& XX.XXX\\
    \bottomrulec
  \end{tabular}
  \caption[Optimal compliance values for different micro-cell models]{%
    Optimal compliance values for the different scenarios
    and micro-cell models (maximum number $\ngpMax = \num{10000}$
    of sparse grid points).
    The columns correspond to the micro-cell models as presented
    in \cref{fig:microCell}:
    2D cross,
    2D framed cross,
    2D shared cross,
    2D shared framed cross,
    3D cross, and
    3D sheared cross.
    The highlighted entries indicate the best choice
    of micro-cell models for a given scenario.%
  }%
  \label{tbl:TODO1}%
\end{table}

\begin{table}
  \setnumberoftableheaderrows{1}%
  \begin{tabular}{%
      >{\kern\tabcolsep}=l<{\kern5mm}*{5}{+c}<{\kern\tabcolsep}%
    }
    \toprulec
    \headerrow
    Scenario&
    $\bspl{\*l,\*i}{1}$&
    $\bspl{\*l,\*i}{3}$&
    $\bspl[\nak]{\*l,\*i}{3}$&
    $\bspl{\*l,\*i}{5}$&
    $\bspl[\nak]{\*l,\*i}{5}$\\
    \midrulec
    2D cantilever&  XX.XXX& XX.XXX& XX.XXX& XX.XXX& XX.XXX\\
    2D L shape&     XX.XXX& XX.XXX& XX.XXX& XX.XXX& XX.XXX\\
    \midrulec
    3D cantilever&  XX.XXX& XX.XXX& XX.XXX& XX.XXX& XX.XXX\\
    3D center load& XX.XXX& XX.XXX& XX.XXX& XX.XXX& XX.XXX\\
    \bottomrulec
  \end{tabular}
  \caption[Optimal compliance values for different basis functions]{%
    Optimal compliance values for the different scenarios
    and basis functions (maximum number $\ngpMax = \num{10000}$
    of sparse grid points).
    The highlighted entries indicate the best choice
    of basis functions for a given scenario.%
  }%
  \label{tbl:TODO2}%
\end{table}

\todo{try different basis types}

\dummytext[12]{}
