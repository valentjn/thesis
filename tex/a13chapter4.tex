\section{Proofs for Chapter 4}

\printornamentsfalse
\subsection{Combinatorial Proof of the Combination Technique}
\label{sec:proofCombiTechnique}
\printornamentstrue

\begin{definition}[binomial coefficient for integer parameters]
  \label{def:binomialCoefficient}
  The binomial coefficient $\binom{n}{k}$ is defined for
  $n, k \in \integer$ as
  \begin{equation}
    \binom{n}{k}
    :=
    \begin{cases}
      \frac{n (n - 1) \dotsm (n - (k-1))}{k!},&k > 0,\\
      1,&k = 0,\\
      0,&k < 0.
    \end{cases}
  \end{equation}
\end{definition}

\begin{lemma}[inclusion-exclusion counting lemma]
  \label{lemma:inclusionExclusionCountingLemma}
  For $m \in \natz$ and $r, s \in \integer$, we have
  \begin{equation}
    \sum_{q=0}^m (-1)^q \binom{m}{q} \binom{r-q}{s}
    = \binom{r-m}{s-m}.
  \end{equation}
\end{lemma}

\begin{proof}
  We apply the upper negation formula
  (see Eq. (5.14) of \cite{Graham94Concrete})
  to the second binomial in the \lhs:
  \begin{subequations}
    \begin{align}
      \sum_{q=0}^m (-1)^q \binom{m}{q} \binom{r-q}{s}
      &= (-1)^s \sum_{q=0}^m \binom{m}{0+q} \binom{(s-r-1)+q}{s} (-1)^q.\\
      \intertext{%
        This sum can be simplified using the identity
        in Eq. (5.24) of \cite{Graham94Concrete}
        (the sum has already been written in the same way as in
        \cite{Graham94Concrete}):%
      }
      %&= (-1)^s (-1)^{m+0} \binom{(s-r-1)-0}{s-m}\\
      &= (-1)^{s+m} \binom{s-r-1}{s-m}.\\
      \intertext{%
        Applying the upper negation formula again,%
      }
      %&= (-1)^{s+m} (-1)^{s-m} \binom{(s-m) - (s-r-1) - 1}{s-m}\\
      &= \binom{r-m}{s-m},
    \end{align}
  \end{subequations}
  we obtain the desired quantity.
\end{proof}

\propCombiTechniqueOne*

\begin{proof}
  Let $q = 0, \dotsc, d - 1$ and $\gp{\*l,\*i} \in \regsgset{n}{d}$, i.e.,
  $\normone{\*l} \le n$ and $\*i \in \hiset{\*l}$.
  Note that for $\*l' \in \natz^d$, we have
  $\fgset{\*l'} \ni \gp{\*l,\*i} \iff \*l' \ge \*l$.
  Hence,
  \begin{subequations}
    \begin{align}
      \setsize{
        \{\*l' \mid \normone{\*l'} = n - q,\; \fgset{\*l'} \ni \gp{\*l,\*i}\}
      }
      &= \setsize{
        \{\*l' \mid \normone{\*l'} = n - q,\; \*l' \ge \*l\}
      }\\
      &= \setsize{
        \{\*a \in \natz^d \mid \normone{\*a} = n - q - \normone{\*l}\}
      }\\
      \intertext{%
        by mapping $\*a := \*l' - \*l$.
        The size of the last set is
        known as the number of weak compositions
        of $n - q - \normone{\*l}$ into $d$ parts
        and can computed as%
      }
      &= \binom{n - q - \normone{\*l} + d - 1}{d - 1},
    \end{align}
  \end{subequations}
  see Theorem 2.2 of \cite{Miklos15Introduction}.
  Now, we can use \cref{lemma:inclusionExclusionCountingLemma}
  with the values
  $m := s := d - 1$ and
  $r := n - \normone{\*l} + d - 1$
  %(note that $r \ge m$ due to $\normone{\*l} \le n$)
  to conclude that the \lhs of the assertion
  \eqref{eq:combiTechniqueOne} equals
  \begin{equation}
    \sum_{q=0}^{d-1} (-1)^q \binom{d-1}{q} \cdot
    \binom{n - q - \normone{\*l} + d - 1}{d - 1}
    = \binom{n - \normone{\*l}}{0}
    = 1,
  \end{equation}
  proving the proposition.
\end{proof}

\begin{shortlemma}
  \label{lemma:combiTechniqueEquivalenceRelation}
  ``$\sim$'' is an equivalence relation.
\end{shortlemma}

\begin{proof}
  We check reflexivity, symmetry, and transitivity of ``$\sim$'':
  \begin{itemize}
    \item
    \emph{Reflexivity:}
    Using the same level $\*l' = \*l''$ implies
    $T_{\*l',\*l'} = \{1, \dotsc, d\}$,
    i.e., $\*l' \sim \*l'$.
    
    \item
    \emph{Symmetry:}
    We have
    $\*l' \sim \*l'' \iff \*l'' \sim \*l'$, since
    $T_{\*l',\*l''} = T_{\*l'',\*l'}$ and
    $\min\{l'_t, l''_t\} = \min\{l''_t, l'_t\}$.
    
    \item
    \emph{Transitivity:}
    Let $\*l' \sim \hat{\*l}$ and $\hat{\*l} \sim \*l''$.
    Then, $T_{\*l',\*l''} \supset T_{\*l',\hat{\*l}} \cap T_{\hat{\*l},\*l''}$.
    Thus, if some $t = 1, \dotsc, d$ with $t \notin T_{\*l',\*l''}$ is given,
    $t \notin T_{\*l',\hat{\*l}}$ or $t \notin T_{\hat{\*l},\*l''}$ holds.
    \begin{itemize}
      \item
      \emph{Case 1:}
      $t \notin T_{\*l',\hat{\*l}}$ and $t \in T_{\hat{\*l},\*l''}$.
      The first statement implies $\min\{l'_t, \hat{l}_t\} \ge l_t$
      and the second statement implies $\hat{l}_t = l''_t$.
      Hence,
      $\min\{l'_t, l''_t\} \ge l_t$.
      
      \item
      \emph{Case 2:}
      $t \notin T_{\*l',\hat{\*l}}$ and $t \in T_{\hat{\*l},\*l''}$.
      Analogously to the first case, we conclude $\min\{l'_t, l''_t\} \ge l_t$.
      
      \item
      \emph{Case 3:}
      $t \notin T_{\*l',\hat{\*l}}$ and $t \notin T_{\hat{\*l},\*l''}$.
      In this case, we have
      $\min\{l'_t, \hat{l}_t\} \ge l_t$ and $\min\{\hat{l}_t, l''_t\} \ge l_t$.
      Hence,
      $\min\{l'_t, l''_t\} \ge l_t$.
    \end{itemize}
    Therefore, it holds $\min\{l'_t, l''_t\} \ge l_t$
    for all $t \notin T_{\*l',\*l''}$, i.e., $\*l' \sim \*l''$.
  \end{itemize}
  This shows that ``$\sim$'' is an equivalence relation.
\end{proof}

\lemmaCombiTechniqueIdenticalValues*

\begin{proof}
  First, we note that $T_{\*l',\*l''} \not= \emptyset$.
  Otherwise, for $T_{\*l',\*l''} = \emptyset$,
  we have $\min\{l'_t, l''_t\} \ge l_t$
  for all $t = 1, \dotsc, d$, which implies $\*l' \ge \*l$, i.e.,
  $\fgset{\*l'} \ni \gp{\*l,\*i}$.
  This contradicts the fact that $\*l' \in L$, where $L$ is defined
  in \eqref{eq:combiTechniqueSpecialLevelSet}
  (which holds as our equivalence relation is only defined on $L$).
  Therefore, $T_{\*l',\*l''} \not= \emptyset$ must hold.
  Without loss of generality,
  let us assume that $T_{\*l',\*l''} = \{1, \dotsc, m\}$
  for some $m \in \{1, \dotsc, d\}$.
  
  Let
  \begin{equation}
    S := \gp{\*l,\*i} + \spn\{\unitvec{1}, \dotsc, \unitvec{m}\}
    = \{\gp{\*l,\*i} + \textstyle\sum_{t=1}^m c_t \unitvec{t} \mid
    c_1, \dotsc, c_m \in \real\}
  \end{equation}
  be the $m$-dimensional affine subspace of $\real^d$
  through $\gp{\*l, \*i}$
  parallel to the dimensions $1, \dotsc, m$,
  where $\unitvec{t}$ is the $t$-th unit basis vector.
  It holds $S \cap \fgset{\*l'} = S \cap \fgset{\*l''}$ due to
  $l'_t = l''_t$ for $t \le m$.%
  \footnote{%
    In more detail:
    If we have an $\gp{\hat{\*l},\hat{\*i}} \in S \cap \fgset{\*l'}$,
    then $\fa{t \le m}{\hat{l}_t \le l'_t = l''_t}$ and
    $\fa{t > m}{\hat{l}_t = l_t \le l''_t}$, i.e.,
    $\hat{\*l} \le \*l''$ and therefore
    $\gp{\hat{\*l},\hat{\*i}} \in S \cap \fgset{\*l''}$.%
  }
  
  On this $m$-dimensional grid $S \cap \fgset{\*l'} = S \cap \fgset{\*l''}$,
  the full grid interpolants $\fgintp{\*l'}$ and $\fgintp{\*l''}$
  coincide, as both interpolate the function values given by
  the objective function $\objfun$:
  \begin{equation}
    \label{eq:proofCombiTechniqueIdenticalValues1}
    \restrictfcn{\fgintp{\*l'}}{S \cap \fgset{\*l'}}
    = \restrictfcn{\objfun}{S \cap \fgset{\*l'}}
    =  \restrictfcn{\fgintp{\*l''}}{S \cap \fgset{\*l'}}.
  \end{equation}
  However, this does not suffice to conclude
  $\fgintp{\*l'}(\gp{\*l,\*i}) = \fgintp{\*l''}(\gp{\*l,\*i})$,
  since $\gp{\*l,\*i} \notin \fgset{\*l'}$.
  
  To this end, we recall from \eqref{eq:interpFullGridMV} that
  \begin{equation}
    \fgintp{\*l'}
    = \sum_{\*i'=\*0}^{\*2^{\*l'}} \interpcoeff{\*l',\*i'}
    \basis{\*l',\*i'},\quad
    \interpcoeff{\*l',\*i'} \in \real.
  \end{equation}
  This implies that the $m$-variate function
  $\restrictfcn{\fgintp{\*l'}}{S \cap \clint{\*0, \*1}}$ can be written as
  \begin{subequations}
    \begin{gather}
      (\restrictfcn{\fgintp{\*l'}}{S \cap \clint{\*0, \*1}})(\*x_{\range{1}{m}})
      = \sum_{\*i'_{\range{1}{m}}=\*0}^{\*2^{\*l'_{\range{1}{m}}}}
      \interpcoefftilde{\*l'_{\range{1}{m}},\*i'_{\range{1}{m}}}
      \basis{\*l'_{\range{1}{m}},\*i'_{\range{1}{m}}}(\*x_{\range{1}{m}}),\quad
      \*x_{\range{1}{m}} \in \clint{0, 1}^m,\\
      \interpcoefftilde{\*l'_{\range{1}{m}},\*i'_{\range{1}{m}}}
      := \sum_{\*i'_{\range{m+1}{d}}=\*0}^{\*2^{\*l'_{\range{m+1}{d}}}}
      \interpcoeff{\*l',\*i'} \cdot
      \basis{\*l'_{\range{m+1}{d}},\*i'_{\range{m+1}{d}}}%
      (\gp{\*l_{\range{m+1}{d}},\*i_{\range{m+1}{d}}})
    \end{gather}
  \end{subequations}
  by factoring out tensor product factors corresponding to dimensions
  $m + 1, \dotsc, d$.
  As a result,
  both $\restrictfcn{\fgintp{\*l'}}{S \cap \clint{\*0, \*1}}$
  and, analogously,
  $\restrictfcn{\fgintp{\*l''}}{S \cap \clint{\*0, \*1}}$
  are interpolants of $f$ in
  $\ns{\*l'_{\range{1}{m}}} = \ns{\*l''_{\range{1}{m}}}$.
  Due to \thmref{lemma:tensorProductLinearIndependence},
  it follows from \eqref{eq:proofCombiTechniqueIdenticalValues1}
  that they must be the same:
  \begin{equation}
    \restrictfcn{\fgintp{\*l'}}{S \cap \clint{\*0, \*1}}
    = \restrictfcn{\fgintp{\*l''}}{S \cap \clint{\*0, \*1}}.
  \end{equation}
  Consequently, $\fgintp{\*l'}(\gp{\*l,\*i}) = \fgintp{\*l''}(\gp{\*l,\*i})$
  as $\gp{\*l,\*i} \in S \cap \clint{\*0, \*1}$.
\end{proof}

\lemmaCombiTechniqueCharacterization*

\begin{proof}
  ``$\subset$'':
  Let $\*l' \in L_0$.
  We have to prove that
  $\fa{t \in T_{L_0}}{l'_t = l^\ast_t}$ and
  $\fa{t \notin T_{L_0}}{l'_t \ge l_t}$.
  The first statement is clear by the definition of $T_{L_0}$.
  Therefore, let $t \notin T_{L_0}$.
  By the definition of $T_{L_0}$,
  there must be some $\hat{\*l}', \hat{\*l}'' \in L_0$ with
  $\hat{l}'_t \not= \hat{l}''_t$.%
  \footnote{%
    $T_{L_0}$ is the set of all dimensions on which all levels
    in $L_0$ coincide.
    If a dimension $t$ is not in $T_{L_0}$, then there must be two levels
    that differ in the $t$-th entry.%
  }
  One of $l'_t \not= \hat{l}'_t$ or $l'_t \not= \hat{l}''_t$ must be true.
  Let us assume $l'_t \not= \hat{l}'_t$ without loss of generality, i.e.,
  $t \notin T_{\*l',\hat{\*l}'}$.
  Due to $\*l' \sim \hat{\*l}'$
  (since $\*l'$ and $\hat{\*l}'$ are both contained in the same
  equivalence class $L_0$),
  we have $\min\{l'_t, \hat{l}'_t\} \ge l_t$.
  This implies $\fa{t \notin T_{L_0}}{l'_t \ge l_t}$ as desired.
  
  ``$\supset$'':
  Let $\*l' \in L$ such that
  $\fa{t \in T_{L_0}}{l'_t = l^\ast_t}$ and
  $\fa{t \notin T_{L_0}}{l'_t \ge l_t}$
  and let $\*l'' \in L_0$ be an arbitrary representative of $L_0$.
  We prove that $\*l' \sim \*l''$ (i.e., $\*l' \in L_0$).
  Note that $T_{L_0} \subset T_{\*l',\*l''}$,
  as $t \in T_{L_0}$ implies
  $l''_t = l^\ast_t$, which can be combined with $l'_t = l^\ast_t$
  to $l'_t = l''_t$, i.e., $t \in T_{\*l',\*l''}$.
  
  To prove the equivalence of $\*l'$ and $\*l''$,
  let $t \notin T_{\*l',\*l''}$.
  This means that $t \notin T_{L_0}$, i.e.,
  there exist some
  $\hat{\*l}', \hat{\*l}'' \in L_0$ with
  $\hat{l}'_t \not= \hat{l}''_t$.
  As above, we assume $l'_t \not= \hat{l}'_t$ without loss of generality, i.e.,
  $t \notin T_{\*l',\hat{\*l}'}$.
  From $\*l'' \sim \hat{\*l}'$
  (since $\*l''$ and $\hat{\*l}'$ are both contained in the same
  equivalence class $L_0$),
  we obtain $\min\{l''_t, \hat{l}'_t\} \ge l_t$.
  Together with $l'_t \ge l_t$ (by the above assumption on $\*l'$),
  this implies
  $\fa{t \notin T_{\*l',\*l''}}{\min\{l'_t, l''_t\} \ge l_t}$
  and consequently $\*l' \sim \*l''$,
  as asserted.
\end{proof}

\propCombiTechniqueZero*

\begin{proof}
  \Cref{lemma:combiTechniqueIdenticalValues}
  implies that the summands $\fgintp{\*l'}(\gp{\*l,\*i})$
  corresponding to levels $\*l'$ of the same equivalence class
  $L_0 \in \eqclasses{L}{\sim}$ are identical.
  Let $f_{L_0}$ denote the common function value.
  Hence, the sum in the \lhs of the assertion can be reordered to combine
  levels of the equivalence classes $L_0 \in \eqclasses{L}{\sim}$:
  \begin{subequations}
    \begin{align}
      &\sum_{q=0}^{d-1} (-1)^q \binom{d-1}{q} \cdot
      \sum_{\substack{\normone{\*l'} = n - q\\\fgset{\*l'} \notni \gp{\*l,\*i}}}
      \fgintp{\*l'}(\gp{\*l,\*i})\\
      \label{eq:proofCombiTechniqueIdenticalValues2}
      &= \sum_{L_0 \in \eqclasses{L}{\sim}} f_{L_0} \sum_{q=0}^{d-1}
      (-1)^q \binom{d-1}{q} \cdot
      \setsize{\{\*l' \in L_0 \mid \normone{\*l'} = n - q\}}.
    \end{align}
  \end{subequations}
  It now suffices to show that the inner sum vanishes
  for every equivalence class $L_0 \in \eqclasses{L}{\sim}$.
  
  To this end, we have to calculate
  $\setsize{\{\*l' \in L_0 \mid \normone{\*l'} = n - q\}}$
  for a fixed equivalence class $L_0$.
  Without loss of generality,
  let $T_{L_0} = \{1, \dotsc, m\}$ in
  \thmref{lemma:combiTechniqueCharacterization}
  with $1 \le m \le d$.
  Note that the case $m = 0$ is impossible:
  Otherwise, $T_{L_0} = \emptyset$ implies
  $\fa{\*l' \in L_0}{\*l' \ge \*l}$ by
  \cref{lemma:combiTechniqueCharacterization}, and
  as equivalence classes are non-empty,
  there is at least one $\*l' \in L_0$ with $\*l' \ge \*l$.
  However, this is equivalent to $\fgset{\*l'} \ni \gp{\*l,\*i}$,
  which contradicts $\*l' \in L$.
  
  To enumerate all the levels $\*l' \in L_0$ with $\normone{\*l'} = n - q$,
  we exploit the characterization of $L_0$ of
  \cref{lemma:combiTechniqueCharacterization}.
  As a shortcut, we define the vector
  \begin{equation}
    \hat{\*l}
    := (l^\ast_1, \dotsc, l^\ast_m,\; l_{m+1}, \dotsc, l_d).
  \end{equation}
  We show that $\*a := (l'_t - l_t)_{t = m+1, \dotsc, d}$,
  constitutes a bijection between
  \begin{equation}
    \{\*l' \in L_0 \mid \normone{\*l'} = n - q\}
    \quad\text{and}\quad
    \{\*a \in \natz^{d-m} \mid \normone{\*a} = n - q - \normone{\hat{\*l}}\}:
  \end{equation}
  \begin{itemize}
    \item
    Let $\*l' \in L_0$ with $\normone{\*l'} = n - q$.
    Then, $\fa{t=m+1,\dotsc,d}{l'_t - l_t \ge 0}$
    (by \cref{lemma:combiTechniqueCharacterization}), i.e.,
    $\*a \in \natz^{d-m}$, and
    \begin{equation}
      \normone{\*a}
      = \sum_{t=m+1}^d (l'_t - l_t)
      = \left(\normone{\*l'} - \sum_{t=1}^m l'_t\right) -
      \sum_{t=m+1}^d \hat{l}_t
      = n - q - \normone{\hat{\*l}}.
    \end{equation}
    
    \item
    Conversely, let $\*a \in \natz^{d-m}$ with
    $\normone{\*a} = n - q - \normone{\hat{\*l}}$.
    If we define $\*l'$ as
    \begin{equation}
      \*l'
      = (l^\ast_1, \dotsc, l^\ast_m,\;
      a_1 + l_{m+1}, \dotsc, a_{d-m} + l_d),
    \end{equation}
    then $\fa{t=1,\dotsc,m}{l'_t = l^\ast_t}$ and
    $\fa{t=m+1,\dotsc,d}{l'_t \ge l_t}$.
    By \cref{lemma:combiTechniqueCharacterization},
    we obtain $\*l' \in L_0$ and
    \begin{equation}
      \normone{\*l'}
      = \normone{\hat{\*l}} + \normone{\*a}
      = n - q.
    \end{equation}
  \end{itemize}
  This bijection implies that
  \begin{subequations}
    \begin{align}
      \setsize{\{\*l' \in L_0 \mid \normone{\*l'} = n - q\}}
      &= \setsize{
        \{\*a \in \natz^{d-m} \mid \normone{\*a} = n - q - \normone{\hat{\*l}}\}
      }.\\
      \intertext{%
        This is the number of weak decompositions of
        $n - q - \normone{\hat{\*l}}$ into $d - m$ parts,
        which can be calculated as%
      }
      &= \binom{n - q - \normone{\hat{\*l}} + d - m - 1}{d - m - 1}.
    \end{align}
  \end{subequations}
  (see Theorem 2.2 of \cite{Miklos15Introduction}).
  We insert this quantity into the inner sum of
  \eqref{eq:proofCombiTechniqueIdenticalValues2}:
  \begin{subequations}
    \begin{align}
      &\sum_{q=0}^{d-1}
      (-1)^q \binom{d-1}{q} \cdot
      \setsize{\{\*l' \in L_0 \mid \normone{\*l'} = n - q\}}\\
      &= \sum_{q=0}^{d-1} (-1)^q \binom{d-1}{q} \cdot
      \binom{n - q - \normone{\hat{\*l}} + d - m - 1}{d - m - 1}\\
      \intertext{%
        Again, we apply \thmref{lemma:inclusionExclusionCountingLemma}
        with the values $m := d - 1$,
        $r := n - \normone{\hat{\*l}} + d - m - 1$, and
        $s := d - m - 1$ to obtain%
      }
      &= \binom{n - \normone{\hat{\*l}} - m}{-m}
      = 0
    \end{align}
  \end{subequations}
  by the convention for binomial coefficients in \cref{def:binomialCoefficient}
  as $-m < 0$.
\end{proof}



\subsection{Correctness Proof of the Method of Residual Interpolation}
\label{sec:proofResidualInterpolation}

\propInvariantResidualInterpolation*

% renames:
% * m --> j
% * m* --> j, m --> j'
% * f^(m) --> r^(j)
% * alpha^(m) --> y^(j)
% * tilde(g)^(m) --> r_{l^(j)}^(j-1)
% * beta^(m) --> alpha^(j)
% * tilde(f)^(m) --> f^{s,j}
% * (1) --> \eqwithref{5}
% * (4) --> \eqwithref{6}
% * (5) --> \eqwithref{1}
% * (6) --> \eqwithref{2}
% * (7) --> \eqwithref{3}

\begin{proof}
  \newcommand*{\eqwithref}[1]{%
    \quad\;%
    \if\relax\detokenize{#1}\relax%
      \mathclap{=}%
    \else%
      \mathclap{\overset{\eqref{eq:propInvariantResidualInterpolation#1}}{=}}%
    \fi%
    \quad\;%
  }%
  %
  We prove the assertion by induction over $j = 1, \dotsc, m$.
  We will need the following equations that follow from the algorithm:
  \begin{subequations}
    \begin{alignat}{2}
      \label{eq:propInvariantResidualInterpolation5}
      r_{\*l^{(j)}}^{(j-1)}(\gp{\*l,\*i})
      &= r^{(j-1)}(\gp{\*l,\*i}),\quad
      &&\*l \le \*l^{(j)},\; \*i \in \hiset{\*l},\\
      \label{eq:propInvariantResidualInterpolation6}
      r^{(j)}(\gp{\*l,\*i})
      &= r^{(j-1)}(\gp{\*l,\*i}) - r_{\*l^{(j)}}^{(j-1)}(\gp{\*l,\*i}),\quad
      &&\*l \in L,\; \*i \in \hiset{\*l}.
    \end{alignat}
  \end{subequations}
  
  \noindent
  \textbf{Induction base case:}
  For $j = 1$, there is nothing to show for
  \eqref{eq:propInvariantResidualInterpolation1}.
  \Cref{eq:propInvariantResidualInterpolation2}
  can be proved as follows:
  \begin{subequations}
    \begin{align}
      r^{(1)}(\gp{\*l,\*i})
      &\eqwithref{6}
      r^{(0)}(\gp{\*l,\*i}) - r_{\*l^{(1)}}^{(0)}(\gp{\*l,\*i})\\
      &\eqwithref{5}
      r^{(0)}(\gp{\*l,\*i}) - r^{(0)}(\gp{\*l,\*i})
      = 0,\qquad
      \*l \le \*l^{(1)},\; \*i \in \hiset{\*l}.
    \end{align}
  \end{subequations}
  \Cref{eq:propInvariantResidualInterpolation3}
  holds as $r_{\*l^{(1)}}^{(0)} = f^{\sparse,(1)}$
  (by \cref{line:algResidualInterpolation2} in
  \cref{alg:residualInterpolation}) and, therefore,
  \begin{align}
    r^{(1)}(\gp{\*l,\*i})
    \eqwithref{6}
    r^{(0)}(\gp{\*l,\*i}) - r_{\*l^{(1)}}^{(0)}(\gp{\*l,\*i})
    = \fcnval{\*l,\*i} - f^{\sparse,(1)}(\gp{\*l,\*i}),\quad
    \*l \in L,\; \*i \in \hiset{\*l}.
  \end{align}
  
  \noindent
  \textbf{Induction step case:}
  We show the three statements for the induction step $j \to j + 1$.
  \begin{itemize}
    \item
    \emph{Showing \eqref{eq:propInvariantResidualInterpolation1} for $j + 1$:}
    Let $j' = 1, \dotsc, j$, $\*l \le \*l^{(j')}$,
    and $\*i \in \hiset{\*l}$.
    Due to the ordering of the levels $\*l^{(1)}, \dotsc, \*l^{(m)}$,
    we can conclude from $j + 1 > j'$ that
    $\normone{\*l^{(j+1)}} \le \normone{\*l^{(j')}}$.
    This implies that there must be a $t' \in \{1, \dotsc, d\}$
    such that $l_{t'}^{(j+1)} \le l_{t'}^{(j')}$.
    Let $S$ be the line in $\real^d$ defined by
    \begin{equation}
      S
      := \gp{\*l,\*i} + \spn\{\unitvec{t'}\}.
    \end{equation}
    
    It holds that $S \cap \fgset{\*l^{(j+1)}} \subset \fgset{\*l^{(j')}}$.
    To show this, let $\gp{\*l',\*i'} \in S \cap \fgset{\*l^{(j+1)}}$
    be arbitrary (with $\*i' \in \hiset{\*l'}$).
    Then, $\fa{t \not= t'}{l'_t = l_t \le l_t^{(j')}}$
    (due to $\gp{\*l',\*i'} \in S$) and
    $l'_{t'} \le l_{t'}^{(j+1)} \le l_{t'}^{(j')}$
    (due to $\gp{\*l',\*i'} \in \fgset{\*l^{(j+1)}}$).
    This means that $\*l' \le \*l^{(j')}$, which implies that
    $\gp{\*l',\*i'} \in \fgset{\*l^{(j')}}$.
    As $\gp{\*l',\*i'}$ is arbitrary,
    this shows $S \cap \fgset{\*l^{(j+1)}} \subset \fgset{\*l^{(j')}}$.
    
    Thus, we infer
    \begin{equation}
      \label{eq:proofPropInvariantResidualInterpolation2}
      r_{\*l^{(j+1)}}^{(j)}(\gp{\*l',\*i'})
      \eqwithref{5}
      r^{(j)}(\gp{\*l',\*i'})
      \eqwithref{2}
      0,\quad
      \gp{\*l',\*i'} \in S \cap \fgset{\*l^{(j+1)}}
      \subset \fgset{\*l^{(j')}},\;
      i' \in \hiset{\*l'},
    \end{equation}
    with the induction hypothesis
    \eqref{eq:propInvariantResidualInterpolation2} for $j$.
    Unfortunately, this does not suffice to directly conclude that
    $r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i}) = 0$ as
    $\gp{\*l,\*i}$ is in general not contained in $\fgset{\*l^{(j+1)}}$.
    
    As in the proof of \cref{lemma:combiTechniqueIdenticalValues},
    we exploit the tensor product nature of the basis functions and
    restrict $r_{\*l^{(j+1)}}^{(j)}$ to $S \cap \clint{0, 1}$:
    \begin{subequations}
      \begin{gather}
        (\restrictfcn{r_{\*l^{(j+1)}}^{(j)}}{S \cap \clint{0, 1}})(x_{t'})
        = \sum_{l'_{t'}=0}^{l_{t'}^{(j+1)}}
        \sum_{i'_{t'} \in \hiset{l'_{t'}}}
        \surplustilde[(j+1)]{l'_{t'},i'_{t'}}
        \basis{l'_{t'},i'_{t'}}(x_{t'}),\quad
        x_{t'} \in \clint{0, 1},\\
        \surplustilde[(j+1)]{l'_{t'},i'_{t'}}
        := \sum_{\*l'_{-t'}=\*0}^{\*l^{(j+1)}_{-t'}}
        \sum_{\*i'_{-t'} \in \hiset{\*l'_{-t'}}}
        \surplus[(j+1)]{\*l',\*i'} \cdot
        \basis{\*l'_{-t'},\*i'_{-t'}}(\gp{\*l_{-t'},\*i_{-t'}}).
        %= \sum_{\*l'=\*0}^{\*l^{(j+1)}} \sum_{\*i' \in \hiset{\*l'}}
        %\surplus[(j+1)]{\*l',\*i'} \basis{\*l',\*i'}
      \end{gather}
    \end{subequations}
    This shows that
    $\restrictfcn{r_{\*l^{(j+1)}}^{(j)}}{S \cap \clint{0, 1}} \in
    \ns{l_{t'}^{(j+1)}}$ is an interpolant of the zero function
    (by \eqref{eq:proofPropInvariantResidualInterpolation2}).
    Due to the linear independence of the univariate basis functions,
    we conclude
    \begin{equation}
      \restrictfcn{r_{\*l^{(j+1)}}^{(j)}}{S \cap \clint{0, 1}}
      \equiv 0.
    \end{equation}
    Consequently, we obtain
    $r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i}) = 0$
    as $\gp{\*l,\*i} \in S \cap \clint{\*0, \*1}$.
    
    \item
    \emph{Showing \eqref{eq:propInvariantResidualInterpolation2} for $j + 1$:}
    Let $j' = 1, \dotsc, j + 1$, $\*l \le \*l^{(j')}$,
    and $\*i \in \hiset{\*l}$.
    For the case $j' \le j$, we obtain
    \begin{equation}
      \label{eq:proofPropInvariantResidualInterpolation1}
      r^{(j+1)}(\gp{\*l,\*i})
      \eqwithref{6}
      r^{(j)}(\gp{\*l,\*i}) - r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i})
      = 0
    \end{equation}
    due to $r^{(j)}(\gp{\*l,\*i}) = 0$ by induction hypothesis
    (\cref{eq:propInvariantResidualInterpolation2}) and
    $r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i}) = 0$ as shown above
    (\cref{eq:propInvariantResidualInterpolation1} for $j + 1$).
    
    For the case $j' = j + 1$,
    \cref{eq:proofPropInvariantResidualInterpolation1}
    still holds as the difference between
    $r^{(j)}(\gp{\*l,\*i})$ and $r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i})$
    vanishes due to \eqref{eq:propInvariantResidualInterpolation5}
    for $j + 1$
    (here, we need $\*l \le \*l^{(j+1)}$).
    
    \item
    \emph{Showing \eqref{eq:propInvariantResidualInterpolation3} for $j + 1$:}
    Let $\*l \in L$ and $\*i \in \hiset{\*l}$.
    Then,
    \begin{subequations}
      \begin{align}
        r^{(j+1)}(\gp{\*l,\*i})
        &\eqwithref{6}
        r^{(j)}(\gp{\*l,\*i}) - r_{\*l^{(j+1)}}^{(j)}(\gp{\*l,\*i})\\
        \intertext{%
          The first term can replaced with the induction hypothesis
          (\eqref{eq:propInvariantResidualInterpolation3} for $j$).
          For the second term, note that
          $r_{\*l^{(j+1)}}^{(j)}
          = \sum_{\*l' \in \levelset} \sum_{\*i' \in \hiset{\*l'}}
          \surplus[(j+1)]{\*l',\*i'} \basis{\*l',\*i'}
          = f^{\sparse,(j+1)} - f^{\sparse,(j)}$ by definition.
          Hence, we obtain%
        }
        &\eqwithref{} (\fcnval{\*l,\*i} - f^{\sparse,(j)}(\gp{\*l,\*i})) -
        (f^{\sparse,(j+1)}(\gp{\*l,\*i}) - f^{\sparse,(j)}(\gp{\*l,\*i}))\\
        &\eqwithref{} \fcnval{\*l,\*i} - f^{\sparse,(j+1)}(\gp{\*l,\*i}),
      \end{align}
    \end{subequations}
    as desired.
  \end{itemize}
  This shows the validity of the statements in
  \eqref{eq:propInvariantResidualInterpolationStatements}
  for $j + 1$.
\end{proof}



\subsection{Correctness Proof of Hierarchization with Breadth-First Search}
\label{sec:proofBFS}

\propInvariantBFS*

\begin{proof}
  We make two observations:
  
  \begin{itemize}
    \item
    First, due to the \bfs nature of \cref{alg:BFS} and the
    hierarchical relation \eqref{eq:directAncestor},
    all grid points with level sum $< q$ are \pop{}ped before
    the first point with level sum $\ge q$ is \pop{}ped.
    
    \item
    Second, after \pop{}ping all grid points with
    level sum $< q$, the output values of the grid points with
    level sum $\le q$ remain unchanged for the rest of the algorithm:
    If \cref{line:algBFS2} of the algorithm updates the output value of a point
    $(\*l, \*i)$ in the iteration of $(\*l', \*i') \in \liset$ with
    $\normone{\*l'} \ge q$, then \cref{line:algBFS1} implies
    $\*l \ge \*l'$ and thus, $\normone{\*l} \ge \normone{\*l'} \ge q$.
    However, $\normone{\*l} = q$ is not possible as
    this would imply that $\normone{\*l} = \normone{\*l'}
    \implies (\*l, \*i) = (\*l', \*i')$ by \cref{line:algBFS1},
    but $(\*l, \*i) = (\*l', \*i')$ is explicitly excluded in the
    \texttt{\algorithmicfor} loop of \cref{line:algBFS1}.
    Therefore, we must have $\normone{\*l} > q$.
    Hence, if a point $(\*l, \*i)$ with level sum $\ge q$ has been \pop{}ped,
    only surpluses of points with level sum $> q$ may be updated.
  \end{itemize}
  
  \noindent
  Now, we prove the asserted claim by induction over $q$.
  
  \noindent
  \textbf{Induction base case:}
  For $q = 0$, \cref{alg:BFS} sets $\linout{\*l,\*i}$ to
  $\fcnval{\*l,\*i}$ in \cref{line:algBFS3}.
  As the sum in \eqref{eq:propInvariantBFS} is empty,
  the claim is correct for $q = 0$.
  
  \noindent
  \textbf{Induction step case:}
  Let $\linout[(q)]{\*l',\*i'}$ and
  $\linout[(q+1)]{\*l',\*i'}$
  be the surpluses after \pop{}ping all
  grid points with level sum $< q$ and $< q + 1$, respectively.
  We show the induction step $q \to q + 1$, i.e.,
  we assume that the assertion is true for $q$
  and prove that after popping all grid points with level sum $< q + 1$,
  it holds
  \begin{equation}
    \label{eq:proofPropInvariantBFS1}
    \linout[(q+1)]{\*l,\*i}
    = \fcnval{\*l,\*i} -
    \sum_{\normone{\*l'} < q+1} \linout[(q+1)]{\*l',\*i'}
    \fundbasis{\*l',\*i'}(\gp{\*l,\*i}),\quad
    (\*l, \*i) \in \liset,\;\;
    \normone{\*l} = q+1.
  \end{equation}
  %Due to the considerations above,
  %the surpluses corresponding to points with level sum $\le q$
  %stay the same.
  Therefore, let $(\*l, \*i) \in \liset$ with $\normone{\*l} = q+1$.
  The update in \cref{line:algBFS2} can safely be applied
  with all grid points $(\*l', \*i')$ with level sum $q$.
  The grid points $(\*l', \*i')$ that do not satisfy the relation in the set in
  \cref{line:algBFS1} do not contribute as
  $\fundbasis{\*l',\*i'}(\gp{\*l,\*i}) = 0$
  due to the necessary condition \eqref{eq:fundamentalPropertyImplicationMV}.
  By summing all updates from \cref{line:algBFS2}, we obtain
  \begin{subequations}
    \begin{align}
      \linout[(q+1)]{\*l,\*i}
      &= \linout[(q)]{\*l,\*i} -
      \sum_{\normone{\*l'} = q} \linout[(q)]{\*l',\*i'}
      \fundbasis{\*l',\*i'}(\gp{\*l,\*i}).\\
      \intertext{%
        After inserting the induction hypothesis
        for $\linout[(q)]{\*l,\*i}$,%
      }
      &= \left(\fcnval{\*l,\*i} -
      \sum_{\normone{\*l'} < q} \linout[(q)]{\*l',\*i'}
      \fundbasis{\*l',\*i'}(\gp{\*l,\*i})\right) -
      \sum_{\normone{\*l'} = q} \linout[(q)]{\*l',\*i'}
      \fundbasis{\*l',\*i'}(\gp{\*l,\*i})\\
      &= \fcnval{\*l,\*i} -
      \sum_{\normone{\*l'} < q + 1} \linout[(q)]{\*l',\*i'}
      \fundbasis{\*l',\*i'}(\gp{\*l,\*i}).
    \end{align}
  \end{subequations}
  As noted above, we have
  $\fa{(\*l', \*i'),\, \norm{\*l'} < q + 1}{
    \linout[(q)]{\*l',\*i'} = \linout[(q+1)]{\*l',\*i'}
  }$
  (the values of points with level sum $< q + 1$
  do not change after \pop{}ping all points with level sum $< q$).
  This shows the induction claim \eqref{eq:proofPropInvariantBFS1}.
\end{proof}
